{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0624c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import importlib\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "import dataprocessing\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3411f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataprocessing' from '/home/alexandre-tonon/SDD/Hackathons/Hackathon_Heart_Rate_Los_Tigros/dataprocessing.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dataprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498bcfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   _STATE  FMONTH     IDATE IMONTH IDAY IYEAR  DISPCODE       SEQNO  \\\n",
      "0     1.0     2.0  02282024     02   28  2024    1100.0  2024000001   \n",
      "1     1.0     2.0  02212024     02   21  2024    1100.0  2024000002   \n",
      "2     1.0     2.0  02212024     02   21  2024    1100.0  2024000003   \n",
      "3     1.0     2.0  02282024     02   28  2024    1100.0  2024000004   \n",
      "4     1.0     2.0  02212024     02   21  2024    1100.0  2024000005   \n",
      "\n",
      "           _PSU  CTELENM1  ...  _LCSCTSN  _LCSPSTF  DRNKANY6      DROCDY4_  \\\n",
      "0  2.024000e+09       1.0  ...       NaN       9.0       2.0  5.397605e-79   \n",
      "1  2.024000e+09       1.0  ...       4.0       9.0       2.0  5.397605e-79   \n",
      "2  2.024000e+09       1.0  ...       4.0       2.0       1.0  1.000000e+02   \n",
      "3  2.024000e+09       1.0  ...       NaN       9.0       2.0  5.397605e-79   \n",
      "4  2.024000e+09       1.0  ...       3.0       9.0       2.0  5.397605e-79   \n",
      "\n",
      "   _RFBING6      _DRNKWK3  _RFDRHV9  _FLSHOT7  _PNEUMO3  _AIDTST4  \n",
      "0       1.0  5.397605e-79       1.0       1.0       2.0       2.0  \n",
      "1       1.0  5.397605e-79       1.0       1.0       1.0       2.0  \n",
      "2       2.0  1.400000e+03       1.0       NaN       NaN       2.0  \n",
      "3       1.0  5.397605e-79       1.0       1.0       1.0       2.0  \n",
      "4       1.0  5.397605e-79       1.0       NaN       NaN       2.0  \n",
      "\n",
      "[5 rows x 301 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 2024 data\n",
    "xpt_file = \"data/LLCP2024.XPT\"\n",
    "\n",
    "df = pd.read_sas(xpt_file, format=\"xport\", encoding=\"utf-8\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3366d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c38a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_target(sample):\n",
    "    if not sample[\"CVDINFR4\"] or not sample[\"CVDCRHD4\"]:\n",
    "        return 0\n",
    "    if sample[\"CVDINFR4\"] == 1 or sample[\"CVDCRHD4\"] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "       \n",
    "\n",
    "df[\"TARGET\"] = df.apply(compute_target, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82652698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/train2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "751ae932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/train2.csv\")\n",
    "\n",
    "import yaml\n",
    "with open(\"features.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "selected_columns = config[\"features\"]\n",
    "selected_columns = [col for col in selected_columns if col in df.columns]\n",
    "selected_columns.append('TARGET')\n",
    "df = df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f64c66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(\n",
    "    df: pd.DataFrame,\n",
    "    test: bool = False,\n",
    "    feature_info=None,            # laissé pour compatibilité (non utilisé ici)\n",
    "    scaler: StandardScaler | None = None,\n",
    "    config_path: str = \"features.yaml\",\n",
    "    codebook_html: str = \"data/USCODE22_LLCP_102523.HTML\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Mode entraînement (test=False) -> retourne (X, y, features_99, scaler)\n",
    "    Mode test (test=True)         -> retourne X (transformé avec scaler fourni)\n",
    "    \"\"\"\n",
    "    # 1) Config + codebook\n",
    "    config, codebook = dataprocessing._load_config_and_codebook(config_path, codebook_html)\n",
    "    features = config['features']\n",
    "\n",
    "    # 2) Sélection colonnes\n",
    "    X = df.copy()\n",
    "\n",
    "    # 3) Typage features via codebook\n",
    "    features_classification = dataprocessing._classify_features(codebook, features)\n",
    "\n",
    "    # 4) Nettoyage / encodage\n",
    "    X, continuous_columns = dataprocessing._clean_and_engineer(X, features_classification)\n",
    "\n",
    "    # 5) Scaling\n",
    "    if test:\n",
    "        if scaler is not None:\n",
    "            X[continuous_columns] = scaler.transform(X[continuous_columns])\n",
    "\n",
    "        if feature_info is not None:\n",
    "            feature_info.remove('ID' if 'ID' in feature_info else None)\n",
    "            X = X[feature_info]\n",
    "            \n",
    "        return X\n",
    "    else:\n",
    "        # y et fit scaler\n",
    "        if 'TARGET' not in df.columns:\n",
    "            raise ValueError(\"Colonne TARGET absente du DataFrame en mode entraînement.\")\n",
    "        y = df['TARGET'].astype(int)\n",
    "\n",
    "        if scaler is not None:\n",
    "            X[continuous_columns] = scaler.fit_transform(X[continuous_columns])\n",
    "\n",
    "        return X, y, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "888360ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[selected_columns]\n",
    "Xtrain, ytrain, scaler = data_processing(df, test=False, scaler=Normalizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fb7f8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on validation set: 0.4205701791270709\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params ={'learning_rate': 0.12072635856604813, \n",
    "         'max_depth': 7,\n",
    "        'min_child_weight': 52,\n",
    "        'threshold': 0.18900926428900747,\n",
    "        'num_boost_round': 109}\n",
    "\n",
    "\n",
    "models_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'learning_rate': params['learning_rate'],\n",
    "    'max_depth': params['max_depth'],\n",
    "    'min_child_weight': params['min_child_weight'],\n",
    "    'seed': 42,\n",
    "}\n",
    "\n",
    "Xtrain.drop('TARGET', axis=1, inplace=True)\n",
    "\n",
    "Xtrain_train, Xtrain_val, ytrain_train, ytrain_val = train_test_split(Xtrain, ytrain, test_size=0.2, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(Xtrain_train, label=ytrain_train)\n",
    "dval = xgb.DMatrix(Xtrain_val, label=ytrain_val)\n",
    "dtest = xgb.DMatrix(Xtrain, label=ytrain)\n",
    "\n",
    "model_xgb = xgb.train(models_params, dtrain, num_boost_round=params['num_boost_round'])\n",
    "predictions_val = model_xgb.predict(dval)\n",
    "predictions_val_binary = (predictions_val > params['threshold']).astype(int)\n",
    "\n",
    "f1 = f1_score(ytrain_val, predictions_val_binary)\n",
    "print(f\"F1-score on validation set: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26d890ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-05 14:02:25,799] A new study created in memory with name: no-name-0d6bd350-2bc4-4ad3-8f41-463e3282c55a\n",
      "[I 2025-11-05 14:02:28,931] Trial 0 finished with value: 0.41622209049594944 and parameters: {'threshold': 0.2320215415678009, 'learning_rate': 0.27115112292925025, 'max_depth': 7, 'min_child_weight': 91}. Best is trial 0 with value: 0.41622209049594944.\n",
      "[I 2025-11-05 14:02:31,415] Trial 1 finished with value: 0.4250605435465064 and parameters: {'threshold': 0.20511387956298652, 'learning_rate': 0.10218879740479005, 'max_depth': 6, 'min_child_weight': 73}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:02:34,035] Trial 2 finished with value: 0.3892431033394356 and parameters: {'threshold': 0.29642849684126094, 'learning_rate': 0.08204271259654036, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:02:35,536] Trial 3 finished with value: 0.4237271945744579 and parameters: {'threshold': 0.21920584793036052, 'learning_rate': 0.18295441848456706, 'max_depth': 4, 'min_child_weight': 53}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:02:36,961] Trial 4 finished with value: 0.41427707199032066 and parameters: {'threshold': 0.17048141846585385, 'learning_rate': 0.04006143090106939, 'max_depth': 3, 'min_child_weight': 84}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:02:40,633] Trial 5 finished with value: 0.41590421326104143 and parameters: {'threshold': 0.16403548120336825, 'learning_rate': 0.1253691709182769, 'max_depth': 8, 'min_child_weight': 68}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:02:42,907] Trial 6 finished with value: 0.39375259510045035 and parameters: {'threshold': 0.1282581543538326, 'learning_rate': 0.049137096808402926, 'max_depth': 3, 'min_child_weight': 99}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:02:47,602] Trial 7 finished with value: 0.3863574844356221 and parameters: {'threshold': 0.11162585224473127, 'learning_rate': 0.25918631296776423, 'max_depth': 8, 'min_child_weight': 86}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:02:50,971] Trial 8 finished with value: 0.3936633418769107 and parameters: {'threshold': 0.1181096071527741, 'learning_rate': 0.19700658346830324, 'max_depth': 4, 'min_child_weight': 19}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:02:53,111] Trial 9 finished with value: 0.4215881883479649 and parameters: {'threshold': 0.22901475013057257, 'learning_rate': 0.1809796269736978, 'max_depth': 3, 'min_child_weight': 80}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:03:00,824] Trial 10 finished with value: 0.40416453319679124 and parameters: {'threshold': 0.27202304097425195, 'learning_rate': 0.11048473763036204, 'max_depth': 10, 'min_child_weight': 39}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:03:04,162] Trial 11 finished with value: 0.4237744657927815 and parameters: {'threshold': 0.20461880980040859, 'learning_rate': 0.22005222684368875, 'max_depth': 5, 'min_child_weight': 48}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:03:08,419] Trial 12 finished with value: 0.4205394865128372 and parameters: {'threshold': 0.17954419515452202, 'learning_rate': 0.2159298101415183, 'max_depth': 6, 'min_child_weight': 56}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:03:12,102] Trial 13 finished with value: 0.4212321280223864 and parameters: {'threshold': 0.19780529759904808, 'learning_rate': 0.23538167051778458, 'max_depth': 5, 'min_child_weight': 33}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:03:15,551] Trial 14 finished with value: 0.41152442677414086 and parameters: {'threshold': 0.2566027599028987, 'learning_rate': 0.14081845055333703, 'max_depth': 5, 'min_child_weight': 68}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:03:20,482] Trial 15 finished with value: 0.41076289523277726 and parameters: {'threshold': 0.1462293697358886, 'learning_rate': 0.08456761748464574, 'max_depth': 7, 'min_child_weight': 68}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:03:23,679] Trial 16 finished with value: 0.4242451433442505 and parameters: {'threshold': 0.20496584450362276, 'learning_rate': 0.16381669345569, 'max_depth': 5, 'min_child_weight': 28}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:03:33,916] Trial 17 finished with value: 0.4166354038265716 and parameters: {'threshold': 0.25413500566803005, 'learning_rate': 0.09588436682081175, 'max_depth': 9, 'min_child_weight': 21}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:03:38,551] Trial 18 finished with value: 0.4230134202616316 and parameters: {'threshold': 0.18852754608470224, 'learning_rate': 0.15874345124818262, 'max_depth': 6, 'min_child_weight': 1}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:03:41,215] Trial 19 finished with value: 0.4125933831376734 and parameters: {'threshold': 0.1490883590411798, 'learning_rate': 0.1552530086375327, 'max_depth': 4, 'min_child_weight': 22}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:03:45,871] Trial 20 finished with value: 0.4143415306826017 and parameters: {'threshold': 0.21215653435393855, 'learning_rate': 0.2975210660969715, 'max_depth': 8, 'min_child_weight': 37}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:03:48,696] Trial 21 finished with value: 0.4204687779567007 and parameters: {'threshold': 0.20444678642891803, 'learning_rate': 0.22862247970297994, 'max_depth': 5, 'min_child_weight': 45}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:03:54,427] Trial 22 finished with value: 0.3174064067927441 and parameters: {'threshold': 0.23935737611274333, 'learning_rate': 0.010659752004992862, 'max_depth': 5, 'min_child_weight': 61}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:00,138] Trial 23 finished with value: 0.4224382689494967 and parameters: {'threshold': 0.19290605005081207, 'learning_rate': 0.19966999885464035, 'max_depth': 6, 'min_child_weight': 28}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:06,142] Trial 24 finished with value: 0.4237280274569825 and parameters: {'threshold': 0.2142518913929762, 'learning_rate': 0.13558127140761442, 'max_depth': 7, 'min_child_weight': 49}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:10,004] Trial 25 finished with value: 0.4143559928443649 and parameters: {'threshold': 0.15907139203795279, 'learning_rate': 0.250952551718033, 'max_depth': 4, 'min_child_weight': 10}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:13,094] Trial 26 finished with value: 0.420661464139725 and parameters: {'threshold': 0.18383070594129985, 'learning_rate': 0.17120492658553604, 'max_depth': 5, 'min_child_weight': 42}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:16,124] Trial 27 finished with value: 0.4236457551542978 and parameters: {'threshold': 0.20128427423879647, 'learning_rate': 0.11499238721283236, 'max_depth': 6, 'min_child_weight': 61}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:18,545] Trial 28 finished with value: 0.41915235773201226 and parameters: {'threshold': 0.24467888013337485, 'learning_rate': 0.20645733975560177, 'max_depth': 5, 'min_child_weight': 74}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:21,493] Trial 29 finished with value: 0.4146711718329171 and parameters: {'threshold': 0.2290254404854798, 'learning_rate': 0.2904662312765707, 'max_depth': 7, 'min_child_weight': 98}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:23,236] Trial 30 finished with value: 0.4023737491272981 and parameters: {'threshold': 0.2721093342201951, 'learning_rate': 0.14555872071406606, 'max_depth': 4, 'min_child_weight': 30}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:27,129] Trial 31 finished with value: 0.42470381120045675 and parameters: {'threshold': 0.2199320181443853, 'learning_rate': 0.12576573123685295, 'max_depth': 7, 'min_child_weight': 46}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:31,747] Trial 32 finished with value: 0.4249013759261041 and parameters: {'threshold': 0.22041807717277698, 'learning_rate': 0.05288494750096372, 'max_depth': 7, 'min_child_weight': 48}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:36,109] Trial 33 finished with value: 0.42411184525519485 and parameters: {'threshold': 0.2212504113651694, 'learning_rate': 0.06389719311831234, 'max_depth': 7, 'min_child_weight': 57}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:41,342] Trial 34 finished with value: 0.42376939283662135 and parameters: {'threshold': 0.22352542942609177, 'learning_rate': 0.07327971297316681, 'max_depth': 8, 'min_child_weight': 51}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:46,945] Trial 35 finished with value: 0.4178646934460888 and parameters: {'threshold': 0.23948376500734336, 'learning_rate': 0.029302515915555525, 'max_depth': 9, 'min_child_weight': 10}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:49,848] Trial 36 finished with value: 0.4201345431789737 and parameters: {'threshold': 0.17211458106360705, 'learning_rate': 0.10730136843782541, 'max_depth': 7, 'min_child_weight': 35}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:52,813] Trial 37 finished with value: 0.42332673084895667 and parameters: {'threshold': 0.20910501722292066, 'learning_rate': 0.05856920826389239, 'max_depth': 6, 'min_child_weight': 26}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:56,733] Trial 38 finished with value: 0.39992726391077704 and parameters: {'threshold': 0.288860654167178, 'learning_rate': 0.09005851618959404, 'max_depth': 8, 'min_child_weight': 43}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:04:59,137] Trial 39 finished with value: 0.4175274198700884 and parameters: {'threshold': 0.24999835199390522, 'learning_rate': 0.12210083177096122, 'max_depth': 6, 'min_child_weight': 15}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:05:02,670] Trial 40 finished with value: 0.4219722835910825 and parameters: {'threshold': 0.23151863781145432, 'learning_rate': 0.05001099666743732, 'max_depth': 7, 'min_child_weight': 76}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:05:06,154] Trial 41 finished with value: 0.4216718572346631 and parameters: {'threshold': 0.22191476175029567, 'learning_rate': 0.032357648222503615, 'max_depth': 7, 'min_child_weight': 55}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:05:09,282] Trial 42 finished with value: 0.42232134383600645 and parameters: {'threshold': 0.21823094747312988, 'learning_rate': 0.06801474494145157, 'max_depth': 7, 'min_child_weight': 62}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:05:12,572] Trial 43 finished with value: 0.41254910640181486 and parameters: {'threshold': 0.2630517235000126, 'learning_rate': 0.10248879283222076, 'max_depth': 8, 'min_child_weight': 90}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:05:15,272] Trial 44 finished with value: 0.4233144621718991 and parameters: {'threshold': 0.19319143209915876, 'learning_rate': 0.0745716496852084, 'max_depth': 6, 'min_child_weight': 56}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:05:18,944] Trial 45 finished with value: 0.3854748603351955 and parameters: {'threshold': 0.2352013323366085, 'learning_rate': 0.014199198043967222, 'max_depth': 7, 'min_child_weight': 65}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:05:22,401] Trial 46 finished with value: 0.4188931684573282 and parameters: {'threshold': 0.18093374681941946, 'learning_rate': 0.12820911426703038, 'max_depth': 8, 'min_child_weight': 76}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:05:24,744] Trial 47 finished with value: 0.4221653394008343 and parameters: {'threshold': 0.21842681747587228, 'learning_rate': 0.17362960860620885, 'max_depth': 6, 'min_child_weight': 47}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:05:28,748] Trial 48 finished with value: 0.42206151433301387 and parameters: {'threshold': 0.19991062400144508, 'learning_rate': 0.059242921418507746, 'max_depth': 9, 'min_child_weight': 82}. Best is trial 1 with value: 0.4250605435465064.\n",
      "[I 2025-11-05 14:05:32,169] Trial 49 finished with value: 0.422039534454092 and parameters: {'threshold': 0.20972510457668664, 'learning_rate': 0.04135139930374081, 'max_depth': 7, 'min_child_weight': 70}. Best is trial 1 with value: 0.4250605435465064.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective_mano(trial):\n",
    "    threshold = trial.suggest_float('threshold', 0.1, 0.3)\n",
    "\n",
    "    params_mano ={\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 100),\n",
    "        'seed': 42,\n",
    "    }\n",
    "\n",
    "    model = xgb.train(params_mano, dtrain, num_boost_round=params['num_boost_round'])\n",
    "    predictions = model.predict(dval)\n",
    "    predictions_binary = (predictions > threshold).astype(int)\n",
    "\n",
    "    f1 = f1_score(ytrain_val, predictions_binary)\n",
    "    return f1\n",
    "\n",
    "study_mano = optuna.create_study(direction='maximize')\n",
    "study_mano.optimize(objective_mano, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0e07ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandre-tonon/anaconda3/envs/sdd_env/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:06:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"num_boost_round\", \"threshold\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on extra set: 0.19070794745611655\n"
     ]
    }
   ],
   "source": [
    "extra = pd.read_csv(\"data/extra.csv\")\n",
    "target = extra['TARGET']\n",
    "best_params_mano = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'learning_rate': study_mano.best_params['learning_rate'],\n",
    "    'max_depth': study_mano.best_params['max_depth'],\n",
    "    'min_child_weight': study_mano.best_params['min_child_weight'],\n",
    "    'num_boost_round': params['num_boost_round'],\n",
    "    'threshold': study_mano.best_params['threshold']\n",
    "}\n",
    "\n",
    "columns = [c for c in Xtrain.columns]\n",
    "columns.append(\"ID\")\n",
    "\n",
    "extra = extra[columns]\n",
    "Xextra = data_processing(extra, test=True, scaler=scaler, feature_info=columns)\n",
    "dextra = xgb.DMatrix(Xextra)\n",
    "model = xgb.train(best_params_mano, dtrain, num_boost_round=best_params_mano['num_boost_round'])\n",
    "\n",
    "predictions_extra = model.predict(dextra)\n",
    "predictions_extra_binary = (predictions_extra > best_params_mano['threshold']).astype(int)\n",
    "f1_extra = f1_score(target, predictions_extra_binary)\n",
    "print(f\"F1-score on extra set: {f1_extra}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760562ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")\n",
    "columns = [c for c in Xtrain.columns]\n",
    "\n",
    "columns.append(\"ID\")\n",
    "test = test[columns]\n",
    "Xtest = data_processing(test, test=True, scaler=scaler, feature_info=columns)\n",
    "\n",
    "dtest_final = xgb.DMatrix(Xtest)\n",
    "predictions_test = model_xgb.predict(dtest_final)\n",
    "predictions_test_binary = (predictions_test > params['threshold']).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test[\"ID\"],\n",
    "    \"TARGET\": predictions_test_binary\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_2024.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
